{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../notebook_preamble.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import altair as alt\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from altair_saver import save\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from ci_mapping.utils.utils import flatten_lists\n",
    "from ci_mapping.data.mag_orm import (Paper, \n",
    "                                     Author,\n",
    "                                     AuthorAffiliation,\n",
    "                                     Affiliation,\n",
    "                                     AffiliationLocation,\n",
    "                                     PaperAuthor,\n",
    "                                     FieldOfStudy,\n",
    "                                     PaperFieldsOfStudy,\n",
    "                                     Conference,\n",
    "                                     Journal, \n",
    "                                     PaperFlag,\n",
    "                                     AffiliationType, \n",
    "                                     AuthorAffiliation, \n",
    "                                     AffiliationLocation, \n",
    "                                     OpenAccess, \n",
    "                                     FosMetadata, \n",
    "                                     Conference)\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the configuration file and create a session.\n",
    "db_config = 'postgres+psycopg2://postgres@localhost/ci_deployment'\n",
    "engine = create_engine(db_config)\n",
    "Session = sessionmaker(engine)\n",
    "s = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tables\n",
    "mag = pd.read_sql(s.query(Paper).statement, s.bind)\n",
    "flag = pd.read_sql(s.query(PaperFlag).statement, s.bind)\n",
    "aff_type = pd.read_sql(s.query(AffiliationType).statement, s.bind)\n",
    "paper_author_aff = pd.read_sql(s.query(AuthorAffiliation).statement, s.bind)\n",
    "\n",
    "# Join papers with flag\n",
    "mag = mag.merge(flag, left_on='id', right_on='id')\n",
    "paper_author_aff = paper_author_aff.drop(['id'], axis=1).merge(aff_type, left_on='affiliation_id', right_on='id')\n",
    "paper_author_aff = paper_author_aff.rename(index=str, columns={'type':'non_company'})\n",
    "paper_author_aff = paper_author_aff.merge(mag[['type', 'year', 'id']], left_on='paper_id', right_on='id')\n",
    "aff_papers = paper_author_aff.drop_duplicates(['affiliation_id', 'paper_id'])\n",
    "aff_location = pd.read_sql(s.query(AffiliationLocation).statement, s.bind)\n",
    "open_access = pd.read_sql(s.query(OpenAccess).statement, s.bind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = pd.read_sql(s.query(Journal).statement, s.bind)\n",
    "conferences = pd.read_sql(s.query(Conference).statement, s.bind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns have null values registered as 'NaN'\n",
    "mag['bibtex_doc_type'] = mag.bibtex_doc_type.replace('NaN', np.nan)\n",
    "mag['publisher'] = mag.publisher.replace('NaN', np.nan)\n",
    "mag['references'] = mag.references.replace('NaN', np.nan)\n",
    "mag['abstract'] = mag.abstract.replace('NaN', np.nan)\n",
    "mag['doi'] = mag.doi.replace('NaN', np.nan)\n",
    "\n",
    "# String to list\n",
    "mag['references'] = mag.references.apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else np.nan)\n",
    "\n",
    "# Change the publication and the bibtex document types\n",
    "publication_type_ = {'0':np.nan, \n",
    "                     '1':'Journal article', \n",
    "                     '2':'Patent', \n",
    "                     '3':'Conference paper',\n",
    "                     '4':'Book chapter',\n",
    "                     '5':'Book',\n",
    "                     '6':'Book reference entry', \n",
    "                     '7':'Dataset', \n",
    "                     '8':'Repository'}\n",
    "\n",
    "bibtext_doc_type_ = {'a':'Journal article', 'b':'Book', 'c':'Book chapter', 'p':'Conference paper'}\n",
    "\n",
    "mag['publication_type'] = mag.publication_type.apply(lambda x: publication_type_[x])\n",
    "mag['bibtex_doc_type'] = mag.bibtex_doc_type.apply(lambda x: bibtext_doc_type_[x] if isinstance(x, str) else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag['month_year'] = pd.to_datetime(mag['date']).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mag.isnull().sum() / mag.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of papers in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Papers per category\n",
    "mag.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annual increase of publications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for cat in mag.type.unique():\n",
    "    frame = pd.DataFrame(mag[mag.type==cat].groupby('year')['id'].count() / mag[mag.type==cat].groupby('year')['id'].count().iloc[0]).reset_index()\n",
    "    frame = pd.DataFrame(frame).rename(index=str, columns={'id':'value'})\n",
    "    frame['type'] = cat\n",
    "    frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_line(point=True).encode(\n",
    "    alt.X('year', axis=alt.Axis(labelFontSize=12, titleFontSize=12)),\n",
    "    alt.Y('value', axis=alt.Axis(labelFontSize=12, titleFontSize=12)),\n",
    "    alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    ").properties(title='Annual publication increase (base year = 2000)').configure_legend(titleFontSize=12, labelFontSize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations through time in categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mag.groupby(['year', 'type'])['citations'].mean()).reset_index()\n",
    "\n",
    "alt.Chart(df).mark_circle(\n",
    "    opacity=1,\n",
    "    stroke='black',\n",
    "    strokeWidth=0.5\n",
    ").encode(\n",
    "    alt.X('year', axis=alt.Axis(labelAngle=0)),\n",
    "    alt.Y('type'),\n",
    "    alt.Size('citations',\n",
    "        scale=alt.Scale(range=[0, 1500]),\n",
    "        legend=alt.Legend(title='Citations')\n",
    "    ),\n",
    "    alt.Color('type', legend=None)\n",
    ").properties(\n",
    "    width=780,\n",
    "    height=150, title='Average citations for AI, CI and AI+CI'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Cross-references in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mag.dropna(subset=['references'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "ai_ci_paper_ids = set(df[df.type=='ai_ci']['id'])\n",
    "\n",
    "for _, row in df[df.type=='ci'].iterrows():\n",
    "    for reference_id in row['references']:\n",
    "        if reference_id in ai_ci_paper_ids:\n",
    "            c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share of publications in AI, CI, AI+CI by firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for (num, comp) in zip([0,1], ['non-Industry', 'Industry']):\n",
    "    for cat in aff_papers.type.unique():\n",
    "        data = aff_papers[aff_papers.non_company==num].drop_duplicates('paper_id')\n",
    "        nominator = data[data.type==cat].groupby('year')['paper_id'].count()\n",
    "        denominator = data[data.type==cat].groupby('year')['paper_id'].count().iloc[0]\n",
    "        frame = pd.DataFrame(nominator / denominator).reset_index()\n",
    "        frame = pd.DataFrame(frame).rename(index=str, columns={'paper_id':'value'})\n",
    "        frame['type'] = cat\n",
    "        frame['category'] = comp\n",
    "        frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point(opacity=1, filled=True, size=50).encode(\n",
    "    alt.X('category:N', title=None),\n",
    "    alt.Y('value:Q',),\n",
    "    alt.Color('type:N', legend=alt.Legend(title=\"Category\")),\n",
    "    alt.Column('year')\n",
    ").properties(\n",
    "    width=25\n",
    ").configure_facet(\n",
    "    spacing=15\n",
    ").configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## International collaborations: % of cross-country teams in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id')\n",
    "df = df.drop_duplicates(['paper_id', 'affiliation_id'])\n",
    "# group countries\n",
    "df = df.groupby(['type', 'year', 'paper_id'])['country'].apply(list)\n",
    "df = pd.DataFrame(df)\n",
    "# binary label showing if a paper had affiliations from different countries\n",
    "df['cross_country_collab'] = df.country.apply(lambda x: 1 if len(set(x)) > 1 else 0)\n",
    "# multiply by 100 to get the proportion\n",
    "df = pd.DataFrame(df.reset_index().groupby(['type', 'year'])['cross_country_collab'].mean() * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = alt.Chart(df).mark_point(opacity=1, filled=True, size=50).encode(\n",
    "    alt.X(\n",
    "        'year',\n",
    "        title=\"Year\",\n",
    "#         sort=alt.EncodingSortField(field=\"delta\", order='descending'),\n",
    "        scale=alt.Scale(zero=False),\n",
    "        axis=alt.Axis(grid=False, labelAngle=0),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        'cross_country_collab',\n",
    "        title=\"(%)\",\n",
    "#         sort='-x',\n",
    "        axis=alt.Axis(grid=False)\n",
    "    ),\n",
    "    color=alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    "    ).properties(\n",
    "        width=750,\n",
    "        title='Cross-country collaboration in AI, CI, AI+CI'\n",
    "    )\n",
    "\n",
    "line = alt.Chart(df).mark_line(strokeWidth=1,color='darkgrey',strokeDash=[1,1]).encode(alt.X('year'),  alt.Y('cross_country_collab'), detail='year')\n",
    "\n",
    "\n",
    "(bubbles + line).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry - academia collaborations: % in AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_author_aff.drop_duplicates(['paper_id', 'affiliation_id'])\n",
    "# group countries\n",
    "df = df.groupby(['type', 'year', 'paper_id'])['non_company'].apply(list)\n",
    "df = pd.DataFrame(df)\n",
    "# binary label showing if a paper had affiliations from industry and academia\n",
    "df['industry_academia_collab'] = df.non_company.apply(lambda x: 1 if len(set(x)) > 1 else 0)\n",
    "# multiply by 100 to get the proportion\n",
    "df = pd.DataFrame(df.reset_index().groupby(['type', 'year'])['industry_academia_collab'].mean() * 100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = alt.Chart(df).mark_point(opacity=1, filled=True, size=50).encode(\n",
    "    alt.X(\n",
    "        'year',\n",
    "        title=\"Year\",\n",
    "#         sort=alt.EncodingSortField(field=\"delta\", order='descending'),\n",
    "        scale=alt.Scale(zero=False),\n",
    "        axis=alt.Axis(grid=False, labelAngle=0),\n",
    "    ),\n",
    "    alt.Y(\n",
    "        'industry_academia_collab',\n",
    "        title=\"(%)\",\n",
    "#         sort='-x',\n",
    "        axis=alt.Axis(grid=False)\n",
    "    ),\n",
    "    color=alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    "    ).properties(\n",
    "        width=750,\n",
    "        title='Industry-academia collaboration in AI, CI, AI+CI'\n",
    "    )\n",
    "\n",
    "line = alt.Chart(df).mark_line(strokeWidth=1,color='darkgrey',strokeDash=[1,1]).encode(alt.X('year'), alt.Y('industry_academia_collab'), detail='year')\n",
    "\n",
    "\n",
    "(bubbles + line).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adoption of open access by AI, CI, AI+CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_journal = mag[['id', 'year', 'type']].merge(journals, left_on='id', right_on='paper_id').merge(open_access, left_on='id_y', right_on='id')\n",
    "\n",
    "frames = []\n",
    "for (num, comp) in zip([0,1], ['Paywalled', 'Preprints']):\n",
    "    for cat in paper_journal.type.unique():\n",
    "        data = paper_journal[paper_journal.open_access==num].drop_duplicates('paper_id')\n",
    "        nominator = data[data.type==cat].groupby('year')['paper_id'].count()\n",
    "        denominator = data[data.type==cat].groupby('year')['paper_id'].count().iloc[0]\n",
    "        frame = pd.DataFrame(nominator / denominator).reset_index()\n",
    "        frame = pd.DataFrame(frame).rename(index=str, columns={'paper_id':'value'})\n",
    "        frame['type'] = cat\n",
    "        frame['category'] = comp\n",
    "        frames.append(frame)\n",
    "    \n",
    "df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_point(opacity=1, filled=True, size=50).encode(\n",
    "    alt.X('category:N', title=None),\n",
    "    alt.Y('value:Q'),\n",
    "    alt.Color('type:N', legend=alt.Legend(title='Category')),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=25\n",
    ").configure_facet(\n",
    "    spacing=15\n",
    ").configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field of Study usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfos = pd.read_sql(s.query(PaperFieldsOfStudy).statement, s.bind)\n",
    "fos = pd.read_sql(s.query(FieldOfStudy).statement, s.bind)\n",
    "pfos = pfos.merge(fos, left_on='field_of_study_id', right_on='id')[['paper_id', 'field_of_study_id', 'name']]\n",
    "fos_metadata = pd.read_sql(s.query(FosMetadata).statement, s.bind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (mag\n",
    "      .merge(pfos[pfos.field_of_study_id.isin(fos_metadata[fos_metadata.level==3]['id'].unique())], \n",
    "             left_on='id', \n",
    "             right_on='paper_id'))\n",
    "df = df[['paper_id', 'type', 'year', 'name']]\n",
    "\n",
    "# Combine most used CI and AI+CI FoS\n",
    "ci_top_fos = df[df.type=='ci'].name.value_counts().index[:20]\n",
    "aici_top_fos = df[df.type=='ai_ci'].name.value_counts().index[:20]\n",
    "combined_fos = [x for x in set(ci_top_fos.append(aici_top_fos)) if x != 'The other' and x!= 'Effect of' and x!='Wide range']\n",
    "# combined_fos = set(ci_top_fos.append(aici_top_fos))\n",
    "\n",
    "df = pd.DataFrame(df.groupby(['type', 'year', 'name'])['paper_id'].count()).reset_index()\n",
    "df = df[df.type.isin(['ci', 'ai_ci'])]\n",
    "df = df[df.name.isin(combined_fos)]\n",
    "\n",
    "df['year'] = df.year.astype(int)\n",
    "\n",
    "lst = []\n",
    "for year in df.year.unique():\n",
    "    for name in df.name.unique():\n",
    "        if len(df[(df.name==name) & (df.year==year)]['type'].values) == 2:\n",
    "            continue\n",
    "        elif len(df[(df.name==name) & (df.year==year)]['type'].values) == 1:\n",
    "            if df[(df.name==name) & (df.year==year)]['type'].values[0] == 'ci':\n",
    "                lst.append({'type':'ai_ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            else:\n",
    "                lst.append({'type':'ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "        else:\n",
    "            lst.append({'type':'ai_ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            lst.append({'type':'ci', 'year':year, 'name':name, 'paper_id':0})\n",
    "            \n",
    "df = pd.concat([df, pd.DataFrame(lst)])\n",
    "\n",
    "fraq = []\n",
    "for _, row in df.iterrows():\n",
    "    fraq.append((row['paper_id'] / df[(df.type==row['type']) & (df.year==row['year'])]['paper_id'].sum()) * 100)\n",
    "    \n",
    "df['fraq'] = fraq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slider = alt.binding_range(min=2000, max=2020, step=1)\n",
    "select_year = alt.selection_single(name='selected', fields=['year'],\n",
    "                                   bind=slider, init={'year': 2000})\n",
    "\n",
    "base = alt.Chart(df).add_selection(\n",
    "    select_year\n",
    ").transform_filter(\n",
    "    select_year\n",
    ").transform_calculate(\n",
    "    category=alt.expr.if_(alt.datum.type == 'ci', 'CI', 'AI+CI')\n",
    ").properties(\n",
    "    width=350,\n",
    ")\n",
    "\n",
    "color_scale = alt.Scale(domain=['CI', 'AI+CI'])\n",
    "\n",
    "left = base.transform_filter(\n",
    "    alt.datum.category == 'CI'\n",
    ").encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    x=alt.X('fraq',\n",
    "            title='(%)', sort=alt.SortOrder('descending'), scale=alt.Scale(domain=[0, 100])),\n",
    "    color=alt.Color('category:N', legend=None)\n",
    ").mark_bar().properties(title='CI', width=270)\n",
    "\n",
    "middle = base.encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    text=alt.Text('name'),\n",
    ").mark_text().properties(width=200)\n",
    "\n",
    "right = base.transform_filter(\n",
    "    alt.datum.category == 'AI+CI'\n",
    ").encode(\n",
    "    y=alt.Y('name', axis=None),\n",
    "    x=alt.X('fraq', title='(%)', scale=alt.Scale(domain=[0, 100])),\n",
    "    color=alt.Color('category:N', scale=color_scale, legend=None)\n",
    ").mark_bar().properties(title='AI+CI', width=270)\n",
    "\n",
    "f = alt.concat(left, middle, right, spacing=5).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(f, '/Users/kstathou/Desktop/fields_of_study_level_3_width_270_scaled_axis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journals and conferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = mag[['type', 'id', 'year']].merge(conferences, left_on='id', right_on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_2008_2013 = conferences[(conferences.year >= '2014') & (conferences.year <= '2020')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_2008_2013 = pd.DataFrame(conf_2008_2013[conf_2008_2013.type=='ci'].groupby('conference_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]\n",
    "ai_ci_2008_2013 = pd.DataFrame(conf_2008_2013[conf_2008_2013.type=='ai_ci'].groupby('conference_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]\n",
    "ai_2008_2013 = pd.DataFrame(conf_2008_2013[conf_2008_2013.type=='ai'].groupby('conference_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ci_2008_2013['category'] = 'AI_CI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ai_ci_2008_2013, ci_2008_2013, ai_2008_2013]).to_csv('~/Desktop/ai_ci_aici_conferences_2014_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alt.Chart(ci_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top CI conferences 2008-2013')\n",
    "b = alt.Chart(ai_ci_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top AI+CI conferences 2008-2013')\n",
    "c = alt.Chart(ai_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top AI conferences 2008-2013')\n",
    "\n",
    "(a|b|c).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alt.Chart(ci_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top CI conferences 2014-2020')\n",
    "b = alt.Chart(ai_ci_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top AI+CI conferences 2014-2020')\n",
    "c = alt.Chart(ai_2008_2013).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('conference_name', sort='-x')).properties(title='Top AI conferences 2014-2020')\n",
    "\n",
    "(a|b|c).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = mag[['type', 'id', 'year']].merge(journals, left_on='id', right_on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journ = journals[(journals.year >= '2014') & (journals.year <= '2020')]\n",
    "ci = pd.DataFrame(journ[journ.type=='ci'].groupby('journal_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]\n",
    "ai_ci = pd.DataFrame(journ[journ.type=='ai_ci'].groupby('journal_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]\n",
    "ai = pd.DataFrame(journ[journ.type=='ai'].groupby('journal_name').paper_id.count().sort_values(ascending=False)).reset_index().iloc[:20]\n",
    "\n",
    "a = alt.Chart(ci).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('journal_name', sort='-x')).properties(title='Top CI journals 2014-2020')\n",
    "b = alt.Chart(ai_ci).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('journal_name', sort='-x')).properties(title='Top AI+CI journals 2014-2020')\n",
    "c = alt.Chart(ai).mark_bar().encode(alt.X('paper_id', title='Number of papers'), alt.Y('journal_name', sort='-x')).properties(title='Top AI journals 2014-2020')\n",
    "\n",
    "(a|b|c).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ci['category'] = 'AI_CI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ai,ci,ai_ci]).to_csv('~/Desktop/ai_ci_aici_journals_2014_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals[journals.type=='ci'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(11379+7079) / 34000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences[conferences.type=='ci'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences = mag[['type', 'id', 'year']].merge(conferences, left_on='id', right_on='paper_id')\n",
    "conferences_recent = conferences[conferences.year>'2014']\n",
    "conf = conferences_recent[conferences_recent.type.isin(['ai', 'ci'])]\n",
    "g = conf[conf.conference_name.isin(conf[conf.type=='ci']['conference_name'].value_counts()[:15].index)].groupby('conference_name')['type'].apply(list)\n",
    "g = g.loc[conf[conf.type=='ci'].conference_name.value_counts()[:15].index]\n",
    "\n",
    "\n",
    "d = defaultdict(list)\n",
    "for idx, item in g.iteritems():\n",
    "    d['Conference'].append(idx)\n",
    "    d['Conference'].append(idx)\n",
    "    d['Category'].append('ai')\n",
    "    d['Value'].append(item.count('ai'))\n",
    "    d['Category'].append('ci')\n",
    "    d['Value'].append(item.count('ci'))\n",
    "    \n",
    "d = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journals = mag[['type', 'id', 'year']].merge(journals, left_on='id', right_on='paper_id')\n",
    "journals_recent = journals[journals.year>'2014']\n",
    "journ = journals_recent[journals_recent.type.isin(['ai', 'ci'])]\n",
    "g = journ[journ.journal_name.isin(journ[journ.type=='ci']['journal_name'].value_counts()[:15].index)].groupby('journal_name')['type'].apply(list)\n",
    "g = g.loc[journ[journ.type=='ci'].journal_name.value_counts()[:15].index]\n",
    "\n",
    "d2 = defaultdict(list)\n",
    "for idx, item in g.iteritems():\n",
    "    d2['Journal'].append(idx)\n",
    "    d2['Journal'].append(idx)\n",
    "    d2['Category'].append('ai')\n",
    "    d2['Value'].append(item.count('ai'))\n",
    "    d2['Category'].append('ci')\n",
    "    d2['Value'].append(item.count('ci'))\n",
    "    \n",
    "d2 = pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_plot = alt.Chart(d).mark_bar().encode(\n",
    "    alt.X('sum(Value)', stack=\"normalize\", axis=alt.Axis(format='%'), title=''),\n",
    "    alt.Y('Conference', sort='-x'),\n",
    "    alt.Color('Category')\n",
    ").properties(title='Top CI conferences')\n",
    "\n",
    "journals_plot = alt.Chart(d2).mark_bar().encode(\n",
    "    alt.X('sum(Value)', stack=\"normalize\", axis=alt.Axis(format='%'), title=''),\n",
    "    alt.Y('Journal', sort='-x'),\n",
    "    alt.Color('Category')\n",
    ").properties(title='Top CI journals')\n",
    "\n",
    "(journals_plot | conferences_plot).configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(d2).mark_bar().encode(\n",
    "    alt.X('sum(Value)', stack=\"normalize\"),\n",
    "    alt.Y('Journals', sort='-x'),\n",
    "    alt.Color('Category')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = conferences[conferences.type.isin(['ai', 'ci'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_conf = conf[conf.type=='ai']['conference_name'].value_counts().index[:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = conf[conf.conference_name.isin(ci_conf)].groupby('conference_name')['type'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_overlap = overlap('conference_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.iloc[5].count('ai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.iloc[5].count('ci')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[conf.year=='2000'].type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(type):\n",
    "    d = defaultdict(list)\n",
    "    for year in sorted(ai.year.unique()):\n",
    "        d['overlap'].append('AI | CI')\n",
    "        d['year'].append(year)\n",
    "        d['score'].append(jaccard_similarity(ai[ai.year==year][type], ci[ci.year==year][type]))\n",
    "        \n",
    "    return pd.DataFrame.from_dict(d).set_index('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_fos = conferences.merge(pfos, left_on='paper_id', right_on='paper_id').merge(fos_metadata, left_on='field_of_study_id', right_on='id')\n",
    "top_aici_conf = list(conference_fos[(conference_fos.type=='ai_ci')].drop_duplicates('paper_id').conference_name.value_counts()[:20].index)\n",
    "cfos = conference_fos[(conference_fos.type=='ai_ci') & (conference_fos.level==2) & (conference_fos.conference_name.isin(top_aici_conf))]\n",
    "g = pd.DataFrame(cfos[(cfos.year>='2009')].groupby('conference_name')['name'].apply(Counter)).reset_index().dropna()\n",
    "G = nx.Graph()\n",
    "for _, row in g[g.name>5].iterrows():\n",
    "    G.add_edge(row['conference_name'], row['level_1'], weight=row['name'])\n",
    "    \n",
    "for node in G.nodes:\n",
    "    if node in g.conference_name.unique():\n",
    "        G.nodes[node]['color'] = '#ff7e0e'\n",
    "    else:\n",
    "        G.nodes[node]['color'] = '#1f76b4'\n",
    "        \n",
    "nx.write_graphml(G, '../../data/processed/conferences_fos_aici_2010_2020.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conference_fos = conferences.merge(pfos, left_on='paper_id', right_on='paper_id').merge(fos_metadata, left_on='field_of_study_id', right_on='id')\n",
    "top_ci_conf = list(conference_fos[(conference_fos.type=='ci')].drop_duplicates('paper_id').conference_name.value_counts()[:20].index)\n",
    "cfos = conference_fos[(conference_fos.type=='ci') & (conference_fos.level==2) & (conference_fos.conference_name.isin(top_ci_conf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = pd.DataFrame(cfos[(cfos.year>='2008') & (cfos.year<='2013')].groupby('conference_name')['name'].apply(Counter)).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame(cfos[(cfos.year>='2009')].groupby('conference_name')['name'].apply(Counter)).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for _, row in g[g.name>5].iterrows():\n",
    "    G.add_edge(row['conference_name'], row['level_1'], weight=row['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes:\n",
    "    if node in g.conference_name.unique():\n",
    "        G.nodes[node]['color'] = '#ff7e0e'\n",
    "    else:\n",
    "        G.nodes[node]['color'] = '#1f76b4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# G.remove_node('Educational technology')\n",
    "# G.remove_node('icalt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G, '../../data/processed/conferences_fos_2010_2020.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fields of study heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (mag\n",
    "      .merge(pfos[pfos.field_of_study_id.isin(fos_metadata[fos_metadata.level.isin([1,2,3,4])]['id'].unique())], \n",
    "             left_on='id', \n",
    "             right_on='paper_id'))\n",
    "df = df[['paper_id', 'type', 'year', 'name']]\n",
    "\n",
    "df = df[df.type!='ai']\n",
    "df = pd.DataFrame(df.groupby(['type', 'year', 'name'])['paper_id'].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df[(df.type=='ai_ci') & (df.paper_id > 20)],\n",
    "    title=\"AI+CI: Most used Fields of Study\"\n",
    ").mark_rect().encode(\n",
    "    alt.X('year'),\n",
    "    alt.Y('name:O', sort='x'),\n",
    "    alt.Color('paper_id', scale=alt.Scale(scheme=\"viridis\"), title='Count'),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('name', title='Field of Study'),\n",
    "        alt.Tooltip('paper_id', title='Count')\n",
    "    ]\n",
    ").properties(width=700, height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(\n",
    "    df[(df.type=='ci') & (df.paper_id > 80)],\n",
    "    title=\"CI: Most used Fields of Study\"\n",
    ").mark_rect().encode(\n",
    "    alt.X('year'),\n",
    "    alt.Y('name:O', sort='x'),\n",
    "    alt.Color('paper_id', scale=alt.Scale(scheme=\"viridis\"), title='Count'),\n",
    "    tooltip=[\n",
    "        alt.Tooltip('name', title='Field of Study'),\n",
    "        alt.Tooltip('paper_id', title='Count')\n",
    "    ]\n",
    ").properties(width=700, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic distribution of AI, CI, AI+CI research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location.dropna(subset=['country'])[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id')\n",
    "df = df.drop_duplicates(['paper_id', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai_ci'].sort_values(ascending=False)).reset_index()\n",
    "ai = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai'].sort_values(ascending=False)).reset_index()\n",
    "ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ci'].sort_values(ascending=False)).reset_index()\n",
    "\n",
    "ci['type'] = 'ci'\n",
    "ai['type'] = 'ai'\n",
    "ai_ci['type'] = 'ai_ci'\n",
    "\n",
    "df = pd.concat([ci, ai_ci])\n",
    "df = df[df.country.isin(['United States', 'China', 'United Kingdom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar(opacity=1).encode(\n",
    "    alt.X('country:N', title=None),\n",
    "    alt.Y('paper_id:Q', title='Number of total publications'),\n",
    "    alt.Color('type:N', legend=alt.Legend(title='Category')),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=40\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ").configure_legend(titleFontSize=12, labelFontSize=12).configure_axis(\n",
    "    labelFontSize=12,\n",
    "    titleFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = paper_author_aff.merge(aff_location.dropna(subset=['country'])[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id')\n",
    "df = df.drop_duplicates(['paper_id', 'country'])\n",
    "\n",
    "ai_ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai_ci'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ai_ci'] * 100).reset_index()\n",
    "ai = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ai'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ai'] * 100).reset_index()\n",
    "ci = pd.DataFrame(df.groupby(['type', 'year', 'country'])['paper_id'].count().loc['ci'].sort_values(ascending=False) / df.groupby(['type', 'year'])['paper_id'].count().loc['ci'] * 100).reset_index()\n",
    "\n",
    "ci['type'] = 'ci'\n",
    "ai['type'] = 'ai'\n",
    "ai_ci['type'] = 'ai_ci'\n",
    "\n",
    "df = pd.concat([ci, ai, ai_ci])\n",
    "df = df[df.country.isin(['United States', 'China', 'United Kingdom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = alt.Chart(df[df.country=='China']).mark_line(point=True).encode(\n",
    "    alt.X('year', axis=alt.Axis(labelFontSize=12, titleFontSize=12)),\n",
    "    alt.Y('paper_id', title='(%)', axis=alt.Axis(labelFontSize=12, titleFontSize=12), scale=alt.Scale(domain=[0, 65])),\n",
    "    alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    ").properties(title='China', width=350)\n",
    "\n",
    "uk = alt.Chart(df[df.country=='United Kingdom']).mark_line(point=True).encode(\n",
    "    alt.X('year', axis=alt.Axis(labelFontSize=12, titleFontSize=12)),\n",
    "    alt.Y('paper_id', title='(%)', axis=alt.Axis(labelFontSize=12, titleFontSize=12), scale=alt.Scale(domain=[0, 65])),\n",
    "    alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    ").properties(title='United Kingdom', width=350)\n",
    "\n",
    "us = alt.Chart(df[df.country=='United States']).mark_line(point=True).encode(\n",
    "    alt.X('year', axis=alt.Axis(labelFontSize=12, titleFontSize=12)),\n",
    "    alt.Y('paper_id', title='(%)', axis=alt.Axis(labelFontSize=12, titleFontSize=12), scale=alt.Scale(domain=[0, 65])),\n",
    "    alt.Color('type', legend=alt.Legend(title=\"Category\")),\n",
    ").properties(title='United States', width=350)\n",
    "\n",
    "(us | uk | china).configure_legend(titleFontSize=12, labelFontSize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_bar(opacity=1).encode(\n",
    "    x=alt.X('country:N', title=None),\n",
    "    y=alt.Y('paper_id:Q', title='(%) of total publications'),\n",
    "    color=alt.Color('type:N'),\n",
    "    column='year'\n",
    ").properties(\n",
    "    width=35\n",
    ").configure_facet(\n",
    "    spacing=18\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Country-level citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_location = aff_location.dropna(subset=['country'])\n",
    "# merge paper_apaper_author_aff with location data\n",
    "df = paper_author_aff.merge(aff_location[['affiliation_id', 'country']], left_on='affiliation_id', right_on='affiliation_id').merge(mag[['id', 'citations']], left_on='paper_id', right_on='id')\n",
    "df = df.drop_duplicates(['paper_id', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_us = df[(df.type=='ci') & (df.country=='United States')][['year', 'citations', 'country']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [WIP] Research spillovers - % of researchers that publish mainly in X that have also published in Y or Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = paper_author_aff.groupby('author_id')['type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_contrib_author_ids = frame.where(frame>1).dropna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_contrib_author_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_author_aff[paper_author_aff.author_id==3022127360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
